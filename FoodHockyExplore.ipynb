{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hockyy/food-101-mlcv/blob/main/FoodHockyExplore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6whlUP4QV0h",
        "outputId": "afce59cb-a298-4bec-8a7f-070c3960a36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "def import_from_google_drive():\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "import_from_google_drive()\n",
        "\n",
        "!rm -rf \"/content/food-101\"\n",
        "!cp -r \"/content/drive/mlcv/\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNbf_KIeVDlf",
        "outputId": "567a8ab1-be44-4900-e04d-e76da5b7a054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Organizing /content/food-101/spaghetti_carbonara\n",
            "spaghetti_carbonara\n",
            "Organizing /content/food-101/takoyaki\n",
            "takoyaki\n",
            "Organizing /content/food-101/seaweed_salad\n",
            "seaweed_salad\n",
            "Organizing /content/food-101/sashimi\n",
            "sashimi\n",
            "Organizing /content/food-101/gnocchi\n",
            "gnocchi\n",
            "Organizing /content/food-101/bread_pudding\n",
            "bread_pudding\n",
            "Organizing /content/food-101/donuts\n",
            "donuts\n",
            "Organizing /content/food-101/garlic_bread\n",
            "garlic_bread\n",
            "Organizing /content/food-101/samosa\n",
            "samosa\n",
            "Organizing /content/food-101/chicken_curry\n",
            "chicken_curry\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def makedir(file_path):\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "def organize_data():\n",
        "  food_prefix = \"/content/food-101\"\n",
        "  food_organized_prefix = \"/content/food-101-ok\"\n",
        "  food_path = f\"{food_prefix}/*\"\n",
        "  food_directories = glob.glob(food_path)\n",
        "  food_directories = [dir for dir in food_directories if (\"test\" not in dir) and (\"validate\" not in dir) and (\"train\" not in dir)]\n",
        "  classes = []\n",
        "  classes_map = dict()\n",
        "  for food_directory in food_directories:\n",
        "    food_name = food_directory.split('/')[3]\n",
        "    # Map each food name to each index\n",
        "    current_label = len(classes)\n",
        "    classes_map[food_name] = current_label\n",
        "    classes.append(food_name)\n",
        "    print(f\"Organizing {food_directory}\")\n",
        "    filenames = glob.glob(f\"{food_directory}/*.jpg\")\n",
        "    train, validate, test = np.split(filenames, [int(len(filenames)*0.8), int(len(filenames)*0.9)])\n",
        "    print(food_name)\n",
        "    os.makedirs(f\"{food_organized_prefix}/train/{food_name}\",exist_ok=True)\n",
        "    os.makedirs(f\"{food_organized_prefix}/validate/{food_name}\",exist_ok=True)\n",
        "    os.makedirs(f\"{food_organized_prefix}/test/{food_name}\",exist_ok=True)\n",
        "    for food_file in train:\n",
        "      food_image_name = food_file.split(\"/\",3)\n",
        "      try:\n",
        "        shutil.move(food_file, f\"{food_organized_prefix}/train/{food_image_name[-1]}\")\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    for food_file in validate:\n",
        "      food_image_name = food_file.split(\"/\",3)\n",
        "      try:\n",
        "        shutil.move(food_file, f\"{food_organized_prefix}/validate/{food_image_name[-1]}\")\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    for food_file in test:\n",
        "      food_image_name = food_file.split(\"/\",3)\n",
        "      try:\n",
        "        shutil.move(food_file, f\"{food_organized_prefix}/test/{food_image_name[-1]}\")\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "  return classes, classes_map\n",
        "\n",
        "classes_food_101, classes_map_food_101 = organize_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/food-101\""
      ],
      "metadata": {
        "id": "cgGQ-IUtd1On"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_generator():\n",
        "  food_organized_prefix = \"/content/food-101-ok\"\n",
        "  train_path = f\"{food_organized_prefix}/train\"\n",
        "  validate_path = f\"{food_organized_prefix}/validate\"\n",
        "  test_path = f\"{food_organized_prefix}/test\"\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  validate_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  image_shape_target = (224,224)\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "          train_path,\n",
        "          target_size=image_shape_target,\n",
        "          color_mode=\"rgb\",\n",
        "          class_mode=\"categorical\",\n",
        "          batch_size=32)\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "          test_path,\n",
        "          target_size=image_shape_target,\n",
        "          color_mode=\"rgb\",\n",
        "          class_mode=\"categorical\",\n",
        "          batch_size=1)\n",
        "  validate_generator = validate_datagen.flow_from_directory(\n",
        "          validate_path,\n",
        "          target_size=image_shape_target,\n",
        "          color_mode=\"rgb\",\n",
        "          class_mode=\"categorical\",\n",
        "          batch_size=1)\n",
        "  return train_generator, validate_generator, test_generator\n",
        "\n",
        "train_gen, test_gen, validate_gen = create_image_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bwcEXMBd-q_",
        "outputId": "d20f9e88-e977-4c3c-ab5a-0d918f95cbf7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 10 classes.\n",
            "Found 1000 images belonging to 10 classes.\n",
            "Found 1000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_leNet_model():\n",
        "  model = keras.Sequential()\n",
        "  # CNN Layer\n",
        "  model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3)))\n",
        "  model.add(layers.AveragePooling2D())\n",
        "  model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.AveragePooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  # Dense Layer\n",
        "  model.add(layers.Dense(units=120, activation='relu'))\n",
        "  model.add(layers.Dense(units=84, activation='relu'))\n",
        "  model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "import os\n",
        "\n",
        "def train_model(model, generator, model_name):\n",
        "  model.save(model_name)\n",
        "  checkpoint_path = f\"{model_name}/cp.ckpt\"\n",
        "  # Create a callback that saves the model's weights\n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "  model.fit(train_gen, epochs = 10,callbacks=[cp_callback])\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPOdHiVFCf9B"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_to_drive(model_name):\n",
        "  shutil.copytree(f\"/content/{model_name}\", f\"/content/drive/MyDrive/mlcv/{model_name}\")"
      ],
      "metadata": {
        "id": "n9lU_DPLhw0V"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def predict_and_assess_model(model, test_generator):\n",
        "  result = model.predict(test_generator)\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "9TY9ZUVQgpLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leNet_model = create_leNet_model()\n",
        "train_model(leNet_model, train_gen, \"lenet\")\n",
        "save_model_to_drive(\"lenet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC8EykCrM3cZ",
        "outputId": "8876727e-b81b-43cd-abdd-e9edbe8472da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: lenet/assets\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 2.1446 - accuracy: 0.2467\n",
            "Epoch 1: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 45s 173ms/step - loss: 2.1446 - accuracy: 0.2467\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 1.7133 - accuracy: 0.4020\n",
            "Epoch 2: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 171ms/step - loss: 1.7133 - accuracy: 0.4020\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 1.4388 - accuracy: 0.5077\n",
            "Epoch 3: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 1.4388 - accuracy: 0.5077\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 1.0345 - accuracy: 0.6486\n",
            "Epoch 4: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 1.0345 - accuracy: 0.6486\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.5895 - accuracy: 0.8091\n",
            "Epoch 5: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.5895 - accuracy: 0.8091\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.9120\n",
            "Epoch 6: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 44s 176ms/step - loss: 0.2880 - accuracy: 0.9120\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.9594\n",
            "Epoch 7: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 171ms/step - loss: 0.1480 - accuracy: 0.9594\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9736\n",
            "Epoch 8: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 171ms/step - loss: 0.0969 - accuracy: 0.9736\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9786\n",
            "Epoch 9: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 171ms/step - loss: 0.0787 - accuracy: 0.9786\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9789\n",
            "Epoch 10: saving model to lenet/cp.ckpt\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.0774 - accuracy: 0.9789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mpmOQdkxiYus"
      },
      "execution_count": 44,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FoodHockyExplore.ipynb",
      "provenance": [],
      "mount_file_id": "1zWWz2rZZmK4nkUGZf8pimJGyPi4NlXf0",
      "authorship_tag": "ABX9TyNl6c412lDO2WLmNNyRicaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}